
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Optimization &#8212; Data science and AI for Bio/medical applications using python</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'statistics_optimization';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Causality" href="statistics_causal.html" />
    <link rel="prev" title="Regression interpretation" href="regression_interpretation.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/dasl.png" class="logo__image only-light" alt="Data science and AI for Bio/medical applications using python - Home"/>
    <script>document.write(`<img src="_static/dasl.png" class="logo__image only-dark" alt="Data science and AI for Bio/medical applications using python - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Coding</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="intro_tools.html">Tools</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="git.html">Git, github</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro_markdown.html">Markdown</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro_unix.html">Unix</a></li>
<li class="toctree-l2"><a class="reference internal" href="html.html">HTML, CSS and javascript</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="ds_python.html">Python</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="basic_python.html">Python basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_programming.html">Python programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="functions.html">Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_practice.html">Python in practice</a></li>
<li class="toctree-l2"><a class="reference internal" href="virtual_environments.html">Virtual Environments</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="data.html">Working with data</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="data_cleaning.html">Data cleaning by example</a></li>


<li class="toctree-l2"><a class="reference internal" href="sqlite.html">SQL via sqlite</a></li>
<li class="toctree-l2"><a class="reference internal" href="pysqlite.html">sqlite in python</a></li>
<li class="toctree-l2"><a class="reference internal" href="data_advanced_databases.html">HDF5</a></li>
<li class="toctree-l2"><a class="reference internal" href="webscraping.html">Webscraping</a></li>
<li class="toctree-l2"><a class="reference internal" href="data_advanced_webscraping.html">Advanced web scraping</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="graphics.html">Graphics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="EDA.html">Exploratory data analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="interactive.html">Interactive graphics</a></li>
<li class="toctree-l2"><a class="reference internal" href="graphics_advanced_interactive.html">Advanced interactive graphics</a></li>



<li class="toctree-l2"><a class="reference internal" href="graphics_theory.html">Theory of graphics</a></li>
<li class="toctree-l2"><a class="reference internal" href="graphics_images.html">Images</a></li>
<li class="toctree-l2"><a class="reference internal" href="convolutions.html">Convolutions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="tooling.html">Extra python tooling</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="tooling_nlp.html">Text processing</a></li>
<li class="toctree-l2"><a class="reference internal" href="numpy.html">Numpy</a></li>
<li class="toctree-l2"><a class="reference internal" href="voila.html">Jupyterwidgets and voila</a></li>
<li class="toctree-l2"><a class="reference internal" href="dash.html">Dash</a></li>
<li class="toctree-l2"><a class="reference internal" href="dash2.html">Dash callbacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="streamlit.html">Streamlit</a></li>
<li class="toctree-l2"><a class="reference internal" href="rBasic.html">Base R</a></li>
<li class="toctree-l2"><a class="reference internal" href="rTidyverse.html">R tidyverse quick example</a></li>
<li class="toctree-l2"><a class="reference internal" href="rFromPython.html">R from python</a></li>
<li class="toctree-l2"><a class="reference internal" href="pythonFromR.html">Python from R</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="statistics.html">Regression models</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="binary_classification.html">Introduction to binary classification</a></li>

<li class="toctree-l2"><a class="reference internal" href="regression_through_the_origin.html">Regression through the origin</a></li>
<li class="toctree-l2"><a class="reference internal" href="regression.html">Continuous prediction with regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="logistic.html">Logistic regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="ml.html">Maximum Likelihood</a></li>
<li class="toctree-l2"><a class="reference internal" href="linearSeparable.html">Linear separable models</a></li>
<li class="toctree-l2"><a class="reference internal" href="linearSeparableSMF.html">Interpretation of linear regression coefficients.</a></li>
<li class="toctree-l2"><a class="reference internal" href="regression_examples.html">Linear models: a classic example</a></li>
<li class="toctree-l2"><a class="reference internal" href="regression_interpretation.html">Regression interpretation</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="statistics_causal.html">Causality</a></li>
<li class="toctree-l2"><a class="reference internal" href="dft.html">DFT</a></li>
<li class="toctree-l2"><a class="reference internal" href="linearModels_FFTs.html">Regression and FFTs</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="nns.html">Neural networks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="basic_regression_pytorch.html">Basic regression in pytorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="logistic_regression_pytorch.html">Logistic regression in pytorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytorch_regression.html">Pytorch by example</a></li>
<li class="toctree-l2"><a class="reference internal" href="convnet_classifier_pytorch.html">Convnet classifier example</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="unsupervised.html">Unsupervised learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="unsupervised_pca_ica.html">Unsupervised learning</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/smart-stats/ds4bio_book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/smart-stats/ds4bio_book/issues/new?title=Issue%20on%20page%20%2Fstatistics_optimization.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/statistics_optimization.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Optimization</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-descent">Gradient descent</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-revisited-with-gradient-descent">Example revisited with gradient descent</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="optimization">
<h1>Optimization<a class="headerlink" href="#optimization" title="Link to this heading">#</a></h1>
<p>Not all problems have closed form opimization results. Instead, we have to rely on algorithms to numerically optmize our parameteris.
To fix our discussion, let $l(\theta)$ be a negative log likelihood or loss function that we want to minimize. Equivalently, they
could be the log likelihood or the negative of a loss function (gain function) that we want to optimize. Since we’ll be focusing
on machine learning, we’ll characterize the problem in the terms of minimization, since most ML algoirthms are focused on minmizing
loss functions.</p>
<p>Consider how we would normally minimize a function. We would typically find the root of the derivative. That is, solving
$l’(\theta) = 0$. However, finding the root simply creates an equally hard problem. What about approximating
$l’(\theta)$ with a line at the current estimate? That is,
$$
l’(\theta) \approx l’\left(\theta^{(0)}\right) + \left(\theta - \theta^{(0)}\right)l’’\left(\theta^{(0)}\right)  = 0,
$$
with the approximation being motivated by Taylor’s theorem, where $l’’$ is the Hessian (second derivative matrix). Solving the right hand equality implies
$$
\theta^{(1)} = \theta^{(0)} - l’’\left(\theta^{(0)}\right)^{-1} l’\left(\theta^{(0)}\right).
$$
The algorithm that then recenters the approximation at $\theta^{(1)}$ and performs another update and so on, is called Newton’s algorithm,
which, as its name implies is a very old technique. This algorithm takes the form of heading in the opposite direction of the
gradient ($- l’\left(\theta^{(0)}\right)$) where the scale of the move is governed by the inverse of the second derivative.</p>
<p>As an example, consider the function $l(\theta) = \theta^p$  for $p$ an even number $\geq 2$. Then $l’(\theta) = p\theta^{p-1}$ and $l’’(\theta) = p(p-1) \theta^{p-2}$. Then,
the update is
$$
\theta^{(1)} = \theta^{(0)} - \theta^{(0)} / (p - 1) = \theta^{(0)} (p-2)/(p-1)
$$
implying $\theta^{(n)} = \theta^{(0)} [(p-2)/ (p - 1)]^n$, which clearly converges to 0, the minimum. It converges in one iteration at $p=2$. The size of the jump at which one moves along the linear
approximation is the inverse of the second derivative, i.e. $1 / [p(p-1) \theta^{p-2}]$.  Thus, one moves more the less convex $l$ is around the minimum. In this case, this results in a convergence rate of $[(p-2) / (p - 1)]^{n}$.</p>
<p>Let’s try it out for $p=4$. Here’s the core of the code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="mi">4</span>
<span class="k">while</span> <span class="p">(</span><span class="n">error</span> <span class="o">&gt;</span> <span class="n">tolerance</span><span class="p">):</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">theta</span> <span class="o">/</span> <span class="p">(</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">p</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">theta</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">noiter</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e3</span><span class="p">)</span>
<span class="n">thetavals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thetavals</span><span class="p">,</span> <span class="n">thetavals</span> <span class="o">**</span> <span class="n">p</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">noiter</span><span class="p">):</span>
    <span class="n">step</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">/</span> <span class="p">(</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">theta</span><span class="p">,</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">step</span><span class="p">,</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">step</span><span class="p">],</span>
             <span class="p">[</span><span class="n">theta</span> <span class="o">**</span> <span class="n">p</span><span class="p">,</span> <span class="n">theta</span> <span class="o">**</span> <span class="n">p</span><span class="p">,</span> <span class="p">(</span><span class="n">theta</span> <span class="o">-</span> <span class="n">step</span><span class="p">)</span> <span class="o">**</span> <span class="n">p</span> <span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">step</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/70ce7630b7dfcc4381b44e88a45c47d1d9ecbde75c7fc612bf348b363ac1ee32.png" src="_images/70ce7630b7dfcc4381b44e88a45c47d1d9ecbde75c7fc612bf348b363ac1ee32.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="ch">#!Rscript -e &#39;install.packages(&quot;pscl&quot;, repos=&quot;https://cloud.r-project.org&quot;)&#39; &amp;&gt; /dev/null</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Installing package into ‘/usr/local/lib/R/site-library’
(as ‘lib’ is unspecified)
trying URL &#39;https://cloud.r-project.org/src/contrib/pscl_1.5.9.tar.gz&#39;
Content type &#39;application/x-gzip&#39; length 3019215 bytes (2.9 MB)
==================================================
downloaded 2.9 MB

* installing *source* package ‘pscl’ ...
** package ‘pscl’ successfully unpacked and MD5 sums checked
** using staged installation
** libs
using C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0’
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c IDEAL.c -o IDEAL.o
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c bayesreg.c -o bayesreg.o
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c check.c -o check.o
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c chol.c -o chol.o
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c crossprod.c -o crossprod.o
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c dmatTOdvec.c -o dmatTOdvec.o
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c dtnorm.c -o dtnorm.o
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c dvecTOdmat.c -o dvecTOdmat.o
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c gaussj.c -o gaussj.o
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c init.c -o init.o
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c pi.c -o pi.o
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c predict.c -o predict.o
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c printmat.c -o printmat.o
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c renormalize.c -o renormalize.o
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c rigamma.c -o rigamma.o
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c rmvnorm.c -o rmvnorm.o
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c updateb.c -o updateb.o
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c updatex.c -o updatex.o
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c updatey.c -o updatey.o
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c util.c -o util.o
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c xchol.c -o xchol.o
gcc -I&quot;/usr/share/R/include&quot; -DNDEBUG       -fpic  -g -O2 -ffile-prefix-map=/build/r-base-14Q6vq/r-base-4.3.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c xreg.c -o xreg.o
gcc -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions -flto=auto -ffat-lto-objects -flto=auto -Wl,-z,relro -o pscl.so IDEAL.o bayesreg.o check.o chol.o crossprod.o dmatTOdvec.o dtnorm.o dvecTOdmat.o gaussj.o init.o pi.o predict.o printmat.o renormalize.o rigamma.o rmvnorm.o updateb.o updatex.o updatey.o util.o xchol.o xreg.o -L/usr/lib/R/lib -lR
installing to /usr/local/lib/R/site-library/00LOCK-pscl/00new/pscl/libs
** R
** data
*** moving datasets to lazyload DB
** inst
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
** building package indices
** installing vignettes
** testing if installed package can be loaded from temporary location
** checking absolute paths in shared objects and dynamic libraries
** testing if installed package can be loaded from final location
** testing if installed package keeps a record of temporary installation path
* DONE (pscl)

The downloaded source packages are in
	‘/tmp/Rtmp7Qk1jI/downloaded_packages’
</pre></div>
</div>
</div>
</div>
<section id="example">
<h2>Example<a class="headerlink" href="#example" title="Link to this heading">#</a></h2>
<p>Poisson regression makes for a good example. Consider a model where $Y_i \sim \mbox{Poisson}(\mu_i)$ where
$\log(\mu_i) = x_i^t \theta$ for covariate vector $x_i$. Then the negative log-likelihood associated with the data up to additive constants in $\theta$ is:</p>
<p>$$
l(\theta) = -\sum_{i=1}^n \left[
y_i x_i^t \theta - e^{x_i^t \theta} \right]
$$</p>
<p>Thus,
$$
l’(\theta) = -\sum_{i=1}^n \left[y_i x_i -  e^{x_i^t \theta} x_i\right]
= - \mathbf{X}^t \mathbf{y} + \mathbf{X}^t e^{\mathbf{X}^t \theta}
$$
$$
l’’(\theta) = \sum_{i=1}^n e^{x_i^t \theta} x_i x_i^t = \mathbf{X}^t \mathrm{Diag}\left(e^{\mathbf{X}^t \theta}\right) \mathbf{X}
$$
where $\mathbf{X}$ contains rows $x_i^t$ and $e^{\mathbf{X}^t \theta}$ is a vector with elements
$\mathbf{X}^t \theta$. Therefore, the update function to go from the current value of $\theta$ to the next is:</p>
<p>$$
U(\theta) = \theta +
\left[\mathbf{X}^t \mathrm{Diag}\left(e^{\mathbf{X}^t \theta}\right) \mathbf{X}\right ]^{-1} \mathbf{X}^t \left[ \mathbf{y} - e^{\mathbf{X}^t \theta}\right].
$$
Thus, our update shifts the current value by a fit from a weighted linear model. In this case, the linear
model has outcome $\mathbf{y} - e^{\mathbf{X}^t \theta}$ (which is $\mathbf{y} - E_\theta[\mathbf{y}]$) design matrix $\mathbf{X}$ and weights
$e^{\mathbf{X}^t \theta}$ (which are $\mathrm{Var}_\theta(\mathbf{Y})$).</p>
<p>Consider an example using the Prussian Horse Kick data. We’ll use <code class="docutils literal notranslate"><span class="pre">rpy2</span></code> to
load the data in from R and plot it. We’ll group the data over other variables and simply
fit a Poisson loglinear model with just an intercept and slope term.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">rpy2.robjects.packages</span> <span class="kn">import</span> <span class="n">importr</span><span class="p">,</span> <span class="n">data</span>
<span class="kn">from</span> <span class="nn">rpy2.robjects.pandas2ri</span> <span class="kn">import</span> <span class="n">py2rpy</span><span class="p">,</span> <span class="n">rpy2py</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>

<span class="n">pscl</span> <span class="o">=</span> <span class="n">importr</span><span class="p">(</span><span class="s1">&#39;pscl&#39;</span><span class="p">)</span>
<span class="n">prussian_r</span> <span class="o">=</span> <span class="n">data</span><span class="p">(</span><span class="n">pscl</span><span class="p">)</span><span class="o">.</span><span class="n">fetch</span><span class="p">(</span><span class="s1">&#39;prussian&#39;</span><span class="p">)[</span><span class="s1">&#39;prussian&#39;</span><span class="p">]</span>
<span class="n">prussian</span> <span class="o">=</span> <span class="n">rpy2py</span><span class="p">(</span><span class="n">prussian_r</span><span class="p">)</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;corp&#39;</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;year&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s1">&#39;year&#39;</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span>  <span class="n">size</span> <span class="o">=</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">prussian</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b715e5b3a491d16c483a7a4f05fb1677820477e340a53c52de5fe9d506d92f4a.png" src="_images/b715e5b3a491d16c483a7a4f05fb1677820477e340a53c52de5fe9d506d92f4a.png" />
</div>
</div>
<p>First let’s fit the model using <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> and print out the coeficients. We normalize the year variable as</p>
<p>$$
\frac{\mbox{Year} - \min(\mbox{Year})}{\max(\mbox{Year}) - \min(\mbox{Year})}.
$$</p>
<p>So our slope coefficient is the proprotion of the total years under study rather than the raw year. This is done for several reasons. It helps us visualize the likelihood for one. Secondly, this is normal practice in deep learning to put coefficients on a common scale to help the algorithms have more unit-free starting points.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">statsmodels.discrete.discrete_model</span> <span class="kn">import</span> <span class="n">Poisson</span>
<span class="n">prussian</span><span class="p">[</span><span class="s1">&#39;itc&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">prussian</span><span class="p">[</span><span class="s1">&#39;year_normalized&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">prussian</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">prussian</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">prussian</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">prussian</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">prussian</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">prussian</span><span class="p">[</span> <span class="p">[</span><span class="s1">&#39;itc&#39;</span><span class="p">,</span> <span class="s1">&#39;year_normalized&#39;</span><span class="p">]</span> <span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">Poisson</span><span class="p">(</span><span class="n">endog</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">exog</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 2.921766
         Iterations 4
                          Poisson Regression Results                          
==============================================================================
Dep. Variable:                      y   No. Observations:                   20
Model:                        Poisson   Df Residuals:                       18
Method:                           MLE   Df Model:                            1
Date:                Sat, 27 Apr 2024   Pseudo R-squ.:                 0.01919
Time:                        14:50:57   Log-Likelihood:                -58.435
converged:                       True   LL-Null:                       -59.579
Covariance Type:            nonrobust   LLR p-value:                    0.1305
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
const          2.0983      0.145     14.502      0.000       1.815       2.382
x1             0.3565      0.236      1.509      0.131      -0.106       0.819
==============================================================================
</pre></div>
</div>
</div>
</div>
<p>Now, let’s define the variables and fit the model using <code class="docutils literal notranslate"><span class="pre">numpy</span></code>. The error is the norm of the step size for that iteration.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<span class="n">tolerance</span> <span class="o">=</span> <span class="mf">.0001</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">nosteps</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">while</span> <span class="p">(</span><span class="n">error</span> <span class="o">&gt;</span> <span class="n">tolerance</span><span class="p">):</span>
    <span class="n">eta</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">theta</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">eta</span><span class="p">)</span>
    <span class="n">var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span> <span class="o">@</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">step</span> <span class="o">=</span>  <span class="n">var</span> <span class="o">@</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span> <span class="o">@</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">+</span> <span class="n">step</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
    <span class="n">nosteps</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span> <span class="p">[</span><span class="n">theta</span><span class="p">,</span> <span class="n">nosteps</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[array([2.09827498, 0.35652129]), 10]
</pre></div>
</div>
</div>
</div>
<p>Notice we get the same answer as the optimization routine in <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code>. In this
setting, the second derivative is more than just useful for fast optimization. Specifically, we can get the standard error of the coefficients witht the square root of the diagonal  of the $\left[\mathbf{X}^t \mathrm{Diag}\left(e^{\mathbf{X}^t \theta}\right) \mathbf{X}\right ]^{-1}$ term on convergence. This is the empirical estimate of the asymptotic standard error for the MLE.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">var</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.14469197 0.23618894]
</pre></div>
</div>
</div>
</div>
<p>Here’s the likelihood, which is very narrow, and the path of the estimates as Newton’s algorithm runs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">like</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span>
    <span class="n">eta</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
    <span class="n">like</span> <span class="o">=</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">y</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">eta</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">like</span><span class="p">)</span> <span class="p">)</span>

<span class="n">beta0_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">2.0983</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="mf">0.145</span><span class="p">,</span> <span class="mf">2.0983</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="mf">0.145</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">beta1_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.3565</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="mf">0.236</span><span class="p">,</span> <span class="mf">0.3565</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="mf">0.236</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="n">l</span> <span class="o">=</span> <span class="p">[</span> <span class="p">[</span><span class="n">like</span><span class="p">([</span><span class="n">beta0</span><span class="p">,</span> <span class="n">beta1</span><span class="p">])</span> <span class="k">for</span> <span class="n">beta1</span> <span class="ow">in</span> <span class="n">beta1_vals</span><span class="p">]</span> <span class="k">for</span> <span class="n">beta0</span> <span class="ow">in</span> <span class="n">beta0_vals</span><span class="p">]</span>

<span class="c1">#plt.imshow(l)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">beta0_vals</span><span class="p">,</span> <span class="n">beta1_vals</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>

<span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
<span class="n">tolerance</span> <span class="o">=</span> <span class="mf">.001</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span> <span class="mf">2.0983</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="mf">0.145</span><span class="p">,</span> <span class="mf">0.3565</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="mf">0.236</span><span class="p">])</span>
<span class="n">nosteps</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">while</span> <span class="p">(</span><span class="n">error</span> <span class="o">&gt;</span> <span class="n">tolerance</span><span class="p">):</span>
    <span class="n">eta</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">theta</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">eta</span><span class="p">)</span>
    <span class="n">var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span> <span class="o">@</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">step</span> <span class="o">=</span>  <span class="n">var</span> <span class="o">@</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span> <span class="o">@</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">+</span> <span class="n">step</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
    <span class="n">nosteps</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span> <span class="p">[</span> <span class="p">(</span><span class="n">theta</span> <span class="o">-</span> <span class="n">step</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">theta</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>  <span class="p">,</span> <span class="p">[</span> <span class="p">(</span><span class="n">theta</span> <span class="o">-</span> <span class="n">step</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span> <span class="n">theta</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;blue&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/444f4db53e7beaf1960b89b5249eb8beb92a83d724bba94fdbb5d643a14f454b.png" src="_images/444f4db53e7beaf1960b89b5249eb8beb92a83d724bba94fdbb5d643a14f454b.png" />
</div>
</div>
</section>
<section id="gradient-descent">
<h2>Gradient descent<a class="headerlink" href="#gradient-descent" title="Link to this heading">#</a></h2>
<p>Often, we can’t calculate a second derivative, as will be the case with neural networks.
We then replace the step size in Newton’s algorithm with a less optimal step size:
$$
\theta^{(1)} = \theta^{(0)} - \epsilon \times l’\left(\theta^{(0)}\right)
$$
where $\epsilon$ is the so-called ``learning rate’’.</p>
<p>Consider our example of trying to minimize $\theta^p$. Then, our update is
$$
\theta^{(1)} = \theta^{(0)} - \epsilon \times p \left[\theta^{(0)}\right]^{p-1}.
$$</p>
<p>Let’s try it out for a few different values of $\epsilon$. The core of the code is simply:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">.01</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">noiter</span><span class="p">):</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">epsilon</span> <span class="o">*</span> <span class="n">p</span> <span class="o">*</span> <span class="n">theta</span> <span class="o">**</span> <span class="p">(</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Here we show the convergence for $\epsilon = .1$ (blue line), $\epsilon = .01$ (red line) and $\epsilon = .001$ (green line).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">theta</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-2</span>
<span class="n">noiter</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e3</span><span class="p">)</span>
<span class="n">thetavals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thetavals</span><span class="p">,</span> <span class="n">thetavals</span> <span class="o">**</span> <span class="n">p</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">noiter</span><span class="p">):</span>
    <span class="n">step</span> <span class="o">=</span> <span class="n">epsilon</span> <span class="o">*</span> <span class="n">p</span> <span class="o">*</span> <span class="n">theta</span> <span class="o">**</span> <span class="p">(</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">theta</span><span class="p">,</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">step</span><span class="p">,</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">step</span><span class="p">],</span>
             <span class="p">[</span><span class="n">theta</span> <span class="o">**</span> <span class="n">p</span><span class="p">,</span> <span class="n">theta</span> <span class="o">**</span> <span class="n">p</span><span class="p">,</span> <span class="p">(</span><span class="n">theta</span> <span class="o">-</span> <span class="n">step</span><span class="p">)</span> <span class="o">**</span> <span class="n">p</span> <span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">step</span>

<span class="n">theta</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-1</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">noiter</span><span class="p">):</span>
    <span class="n">step</span> <span class="o">=</span> <span class="n">epsilon</span> <span class="o">*</span> <span class="n">p</span> <span class="o">*</span> <span class="n">theta</span> <span class="o">**</span> <span class="p">(</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">theta</span><span class="p">,</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">step</span><span class="p">,</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">step</span><span class="p">],</span>
             <span class="p">[</span><span class="n">theta</span> <span class="o">**</span> <span class="n">p</span><span class="p">,</span> <span class="n">theta</span> <span class="o">**</span> <span class="n">p</span><span class="p">,</span> <span class="p">(</span><span class="n">theta</span> <span class="o">-</span> <span class="n">step</span><span class="p">)</span> <span class="o">**</span> <span class="n">p</span> <span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;blue&#39;</span><span class="p">)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">step</span>

<span class="n">theta</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="mf">.001</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">noiter</span><span class="p">):</span>
    <span class="n">step</span> <span class="o">=</span> <span class="n">epsilon</span> <span class="o">*</span> <span class="n">p</span> <span class="o">*</span> <span class="n">theta</span> <span class="o">**</span> <span class="p">(</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">theta</span><span class="p">,</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">step</span><span class="p">,</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">step</span><span class="p">],</span>
             <span class="p">[</span><span class="n">theta</span> <span class="o">**</span> <span class="n">p</span><span class="p">,</span> <span class="n">theta</span> <span class="o">**</span> <span class="n">p</span><span class="p">,</span> <span class="p">(</span><span class="n">theta</span> <span class="o">-</span> <span class="n">step</span><span class="p">)</span> <span class="o">**</span> <span class="n">p</span> <span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;green&#39;</span><span class="p">)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">step</span>


<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/71aaee0c789e2352bc16a2611a74e0bf52d4c4d3e763d62291e4ee33ace1c1f4.png" src="_images/71aaee0c789e2352bc16a2611a74e0bf52d4c4d3e763d62291e4ee33ace1c1f4.png" />
</div>
</div>
</section>
<section id="example-revisited-with-gradient-descent">
<h2>Example revisited with gradient descent<a class="headerlink" href="#example-revisited-with-gradient-descent" title="Link to this heading">#</a></h2>
<p>Let’s run the same data throw the gradient descent algorithm rather than Newton’s method.
Here we set the learning rate to b 0.001 for a thousand iterations. The gist of the code is simply:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="mf">.001</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">eta</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">theta</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">eta</span><span class="p">)</span>
    <span class="n">step</span> <span class="o">=</span>  <span class="o">-</span> <span class="n">epsilon</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span> <span class="o">@</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">step</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">theta</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([2.09827498, 0.35652129])
</pre></div>
</div>
</div>
</div>
<p>Stopping the algorithm is a little trickier for gradient descent, since the change at each iteration is dependent on the learning rate. Small learning rates will lead to small step sizes. Here’s a plot of the covergence on top of contours of the likelihood.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#| echo: false</span>

<span class="n">plt</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">beta0_vals</span><span class="p">,</span> <span class="n">beta1_vals</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="mf">.001</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span> <span class="mf">2.0983</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="mf">0.145</span><span class="p">,</span> <span class="mf">0.3565</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="mf">0.236</span><span class="p">])</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">eta</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">theta</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">eta</span><span class="p">)</span>
    <span class="n">step</span> <span class="o">=</span>  <span class="n">epsilon</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span> <span class="o">@</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">+</span> <span class="n">step</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span> <span class="p">[</span> <span class="p">(</span><span class="n">theta</span> <span class="o">-</span> <span class="n">step</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">theta</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>  <span class="p">,</span>
              <span class="p">[</span> <span class="p">(</span><span class="n">theta</span> <span class="o">-</span> <span class="n">step</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span> <span class="n">theta</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span>
              <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;blue&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a09b683b84921912029eb7a5ec054c54cb08d92f0f50a3be4c97a03443977174.png" src="_images/a09b683b84921912029eb7a5ec054c54cb08d92f0f50a3be4c97a03443977174.png" />
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="regression_interpretation.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Regression interpretation</p>
      </div>
    </a>
    <a class="right-next"
       href="statistics_causal.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Causality</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-descent">Gradient descent</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-revisited-with-gradient-descent">Example revisited with gradient descent</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Brian Caffo
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>