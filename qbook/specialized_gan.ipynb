{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GANs\n",
        "\n",
        "GANs, generatlized adversarial networks, are ways to use deep learning\n",
        "to generate data that has very high fidelity to a set of actual\n",
        "data. If you haven't seen some of the generated images from GANs,\n",
        "check them out! We'll try a very simple version where we're going to\n",
        "generate cryptopunks. I drew heavily from\n",
        "[here](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)\n",
        "for all of the code.\n",
        "\n",
        "## GAN implementations\n",
        "\n",
        "GANs work by two parts. I'll describe this by imagining breaking our\n",
        "autoencoder into two parts. Recall, our autoencoder diagram as seen\n",
        "below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sklearn as skl\n",
        "\n",
        "#plt.figure(figsize=[2, 2])\n",
        "G = nx.DiGraph()\n",
        "G.add_node(\"X1\",  pos = (0, 5) )\n",
        "G.add_node(\"X2\",  pos = (1, 5) )\n",
        "G.add_node(\"X3\",  pos = (2, 5) )\n",
        "G.add_node(\"X4\",  pos = (3, 5) )\n",
        "G.add_node(\"X5\",  pos = (4, 5) )\n",
        "G.add_node(\"X6\",  pos = (5, 5) )\n",
        "G.add_node(\"X7\",  pos = (6, 5) )\n",
        "G.add_node(\"X8\",  pos = (7, 5) )\n",
        "\n",
        "G.add_node(\"H11\",  pos = (1.4, 4) )\n",
        "G.add_node(\"H12\",  pos = (2.8, 4) )\n",
        "G.add_node(\"H13\",  pos = (4.2, 4) )\n",
        "G.add_node(\"H14\",  pos = (5.6, 4) )\n",
        "\n",
        "G.add_node(\"H21\",  pos = (2.1, 3) )\n",
        "G.add_node(\"H22\",  pos = (4.9, 3) )\n",
        "\n",
        "G.add_node(\"H31\",  pos = (1.4, 2) )\n",
        "G.add_node(\"H32\",  pos = (2.8, 2) )\n",
        "G.add_node(\"H33\",  pos = (4.2, 2) )\n",
        "G.add_node(\"H34\",  pos = (5.6, 2) )\n",
        "\n",
        "\n",
        "G.add_node(\"H41\",  pos = (0, 1) )\n",
        "G.add_node(\"H42\",  pos = (1, 1) )\n",
        "G.add_node(\"H43\",  pos = (2, 1) )\n",
        "G.add_node(\"H44\",  pos = (3, 1) )\n",
        "G.add_node(\"H45\",  pos = (4, 1) )\n",
        "G.add_node(\"H46\",  pos = (5, 1) )\n",
        "G.add_node(\"H47\",  pos = (6, 1) )\n",
        "G.add_node(\"H48\",  pos = (7, 1) )\n",
        "\n",
        "G.add_edges_from([ (\"X1\", \"H11\"),  (\"X1\", \"H12\"),  (\"X1\", \"H13\"),  (\"X1\", \"H14\")])\n",
        "G.add_edges_from([ (\"X2\", \"H11\"),  (\"X2\", \"H12\"),  (\"X2\", \"H13\"),  (\"X2\", \"H14\")])\n",
        "G.add_edges_from([ (\"X3\", \"H11\"),  (\"X3\", \"H12\"),  (\"X3\", \"H13\"),  (\"X3\", \"H14\")])\n",
        "G.add_edges_from([ (\"X4\", \"H11\"),  (\"X4\", \"H12\"),  (\"X4\", \"H13\"),  (\"X4\", \"H14\")])\n",
        "G.add_edges_from([ (\"X5\", \"H11\"),  (\"X5\", \"H12\"),  (\"X5\", \"H13\"),  (\"X5\", \"H14\")])\n",
        "G.add_edges_from([ (\"X6\", \"H11\"),  (\"X6\", \"H12\"),  (\"X6\", \"H13\"),  (\"X6\", \"H14\")])\n",
        "G.add_edges_from([ (\"X7\", \"H11\"),  (\"X7\", \"H12\"),  (\"X7\", \"H13\"),  (\"X7\", \"H14\")])\n",
        "G.add_edges_from([ (\"X8\", \"H11\"),  (\"X8\", \"H12\"),  (\"X8\", \"H13\"),  (\"X8\", \"H14\")])\n",
        "\n",
        "G.add_edges_from([ (\"H11\", \"H21\"),  (\"H11\", \"H22\")])\n",
        "G.add_edges_from([ (\"H12\", \"H21\"),  (\"H12\", \"H22\")])\n",
        "G.add_edges_from([ (\"H13\", \"H21\"),  (\"H13\", \"H22\")])\n",
        "G.add_edges_from([ (\"H14\", \"H21\"),  (\"H14\", \"H22\")])\n",
        "\n",
        "\n",
        "G.add_edges_from([ (\"H21\", \"H31\"),  (\"H21\", \"H32\"),  (\"H21\", \"H33\"),  (\"H21\", \"H34\")])\n",
        "G.add_edges_from([ (\"H22\", \"H31\"),  (\"H22\", \"H32\"),  (\"H22\", \"H33\"),  (\"H22\", \"H34\")])\n",
        "\n",
        "G.add_edges_from([ (\"H31\", \"H41\"),  (\"H31\", \"H42\"),  (\"H31\", \"H43\"),  (\"H31\", \"H44\")])\n",
        "G.add_edges_from([ (\"H31\", \"H45\"),  (\"H31\", \"H46\"),  (\"H31\", \"H47\"),  (\"H31\", \"H48\")])\n",
        "G.add_edges_from([ (\"H32\", \"H41\"),  (\"H32\", \"H42\"),  (\"H32\", \"H43\"),  (\"H32\", \"H44\")])\n",
        "G.add_edges_from([ (\"H32\", \"H45\"),  (\"H32\", \"H46\"),  (\"H32\", \"H47\"),  (\"H32\", \"H48\")])\n",
        "G.add_edges_from([ (\"H33\", \"H41\"),  (\"H33\", \"H42\"),  (\"H33\", \"H43\"),  (\"H33\", \"H44\")])\n",
        "G.add_edges_from([ (\"H33\", \"H45\"),  (\"H33\", \"H46\"),  (\"H33\", \"H47\"),  (\"H33\", \"H48\")])\n",
        "G.add_edges_from([ (\"H34\", \"H41\"),  (\"H34\", \"H42\"),  (\"H34\", \"H43\"),  (\"H34\", \"H44\")])\n",
        "G.add_edges_from([ (\"H34\", \"H45\"),  (\"H34\", \"H46\"),  (\"H34\", \"H47\"),  (\"H34\", \"H48\")])\n",
        "\n",
        "#G.add_edges_from([(\"H11\", \"H21\"), (\"H11\", \"H22\"), (\"H12\", \"H21\"), (\"H12\", \"H22\")])\n",
        "#G.add_edges_from([(\"H21\", \"Y\"), (\"H22\", \"Y\")])\n",
        "nx.draw(G, \n",
        "        nx.get_node_attributes(G, 'pos'), \n",
        "        with_labels=True, \n",
        "        font_weight='bold', \n",
        "        node_size = 1000,\n",
        "        node_color = \"lightblue\",\n",
        "        linewidths = 3)\n",
        "ax= plt.gca()\n",
        "ax.collections[0].set_edgecolor(\"#000000\")\n",
        "ax.set_xlim([-.5, 7.5])\n",
        "ax.set_ylim([.5, 5.5])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Again, consider breaking this digram into two parts. One that takes\n",
        "the embedding and spits out images (a generator) and one that takes in\n",
        "images and spits out guesses as to whether or not they are real (a\n",
        "discriminator). See below where the generator is on the left and the\n",
        "discriminator is on the right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#plt.figure(figsize=[2, 2])\n",
        "G = nx.DiGraph()\n",
        "\n",
        "\n",
        "#plt.figure(figsize=[2, 2])\n",
        "G = nx.DiGraph()\n",
        "G.add_node(\"X1\",  pos = ( 8, 5) )\n",
        "G.add_node(\"X2\",  pos = ( 9, 5) )\n",
        "G.add_node(\"X3\",  pos = (10, 5) )\n",
        "G.add_node(\"X4\",  pos = (11, 5) )\n",
        "G.add_node(\"X5\",  pos = (12, 5) )\n",
        "G.add_node(\"X6\",  pos = (13, 5) )\n",
        "G.add_node(\"X7\",  pos = (14, 5) )\n",
        "G.add_node(\"X8\",  pos = (15, 5) )\n",
        "\n",
        "G.add_node(\"D11\",  pos = ( 9.4, 4) )\n",
        "G.add_node(\"D12\",  pos = (10.8, 4) )\n",
        "G.add_node(\"D13\",  pos = (12.2, 4) )\n",
        "G.add_node(\"D14\",  pos = (13.6, 4) )\n",
        "\n",
        "G.add_node(\"D21\",  pos = (10.1, 3) )\n",
        "G.add_node(\"D22\",  pos = (12.9, 3) )\n",
        "\n",
        "G.add_node( \"Y\",   pos = (11.5, 2) )\n",
        "\n",
        "G.add_node(\"H21\",  pos = (2.1, 3) )\n",
        "G.add_node(\"H22\",  pos = (4.9, 3) )\n",
        "\n",
        "G.add_node(\"H31\",  pos = (1.4, 2) )\n",
        "G.add_node(\"H32\",  pos = (2.8, 2) )\n",
        "G.add_node(\"H33\",  pos = (4.2, 2) )\n",
        "G.add_node(\"H34\",  pos = (5.6, 2) )\n",
        "\n",
        "\n",
        "G.add_node(\"H41\",  pos = (0, 1) )\n",
        "G.add_node(\"H42\",  pos = (1, 1) )\n",
        "G.add_node(\"H43\",  pos = (2, 1) )\n",
        "G.add_node(\"H44\",  pos = (3, 1) )\n",
        "G.add_node(\"H45\",  pos = (4, 1) )\n",
        "G.add_node(\"H46\",  pos = (5, 1) )\n",
        "G.add_node(\"H47\",  pos = (6, 1) )\n",
        "G.add_node(\"H48\",  pos = (7, 1) )\n",
        "\n",
        "G.add_edges_from([ (\"X1\", \"D11\"),  (\"X1\", \"D12\"),  (\"X1\", \"D13\"),  (\"X1\", \"D14\")])\n",
        "G.add_edges_from([ (\"X2\", \"D11\"),  (\"X2\", \"D12\"),  (\"X2\", \"D13\"),  (\"X2\", \"D14\")])\n",
        "G.add_edges_from([ (\"X3\", \"D11\"),  (\"X3\", \"D12\"),  (\"X3\", \"D13\"),  (\"X3\", \"D14\")])\n",
        "G.add_edges_from([ (\"X4\", \"D11\"),  (\"X4\", \"D12\"),  (\"X4\", \"D13\"),  (\"X4\", \"D14\")])\n",
        "G.add_edges_from([ (\"X5\", \"D11\"),  (\"X5\", \"D12\"),  (\"X5\", \"D13\"),  (\"X5\", \"D14\")])\n",
        "G.add_edges_from([ (\"X6\", \"D11\"),  (\"X6\", \"D12\"),  (\"X6\", \"D13\"),  (\"X6\", \"D14\")])\n",
        "G.add_edges_from([ (\"X7\", \"D11\"),  (\"X7\", \"D12\"),  (\"X7\", \"D13\"),  (\"X7\", \"D14\")])\n",
        "G.add_edges_from([ (\"X8\", \"D11\"),  (\"X8\", \"D12\"),  (\"X8\", \"D13\"),  (\"X8\", \"D14\")])\n",
        "\n",
        "G.add_edges_from([ (\"D11\", \"D21\"),  (\"D11\", \"D22\")])\n",
        "G.add_edges_from([ (\"D12\", \"D21\"),  (\"D12\", \"D22\")])\n",
        "G.add_edges_from([ (\"D13\", \"D21\"),  (\"D13\", \"D22\")])\n",
        "G.add_edges_from([ (\"D14\", \"D21\"),  (\"D14\", \"D22\")])\n",
        "\n",
        "\n",
        "G.add_edges_from([ (\"D21\", \"Y\"),  (\"D22\", \"Y\")])\n",
        "\n",
        "\n",
        "G.add_edges_from([ (\"H21\", \"H31\"),  (\"H21\", \"H32\"),  (\"H21\", \"H33\"),  (\"H21\", \"H34\")])\n",
        "G.add_edges_from([ (\"H22\", \"H31\"),  (\"H22\", \"H32\"),  (\"H22\", \"H33\"),  (\"H22\", \"H34\")])\n",
        "\n",
        "G.add_edges_from([ (\"H31\", \"H41\"),  (\"H31\", \"H42\"),  (\"H31\", \"H43\"),  (\"H31\", \"H44\")])\n",
        "G.add_edges_from([ (\"H31\", \"H45\"),  (\"H31\", \"H46\"),  (\"H31\", \"H47\"),  (\"H31\", \"H48\")])\n",
        "G.add_edges_from([ (\"H32\", \"H41\"),  (\"H32\", \"H42\"),  (\"H32\", \"H43\"),  (\"H32\", \"H44\")])\n",
        "G.add_edges_from([ (\"H32\", \"H45\"),  (\"H32\", \"H46\"),  (\"H32\", \"H47\"),  (\"H32\", \"H48\")])\n",
        "G.add_edges_from([ (\"H33\", \"H41\"),  (\"H33\", \"H42\"),  (\"H33\", \"H43\"),  (\"H33\", \"H44\")])\n",
        "G.add_edges_from([ (\"H33\", \"H45\"),  (\"H33\", \"H46\"),  (\"H33\", \"H47\"),  (\"H33\", \"H48\")])\n",
        "G.add_edges_from([ (\"H34\", \"H41\"),  (\"H34\", \"H42\"),  (\"H34\", \"H43\"),  (\"H34\", \"H44\")])\n",
        "G.add_edges_from([ (\"H34\", \"H45\"),  (\"H34\", \"H46\"),  (\"H34\", \"H47\"),  (\"H34\", \"H48\")])\n",
        "\n",
        "\n",
        "#G.add_edges_from([(\"H11\", \"H21\"), (\"H11\", \"H22\"), (\"H12\", \"H21\"), (\"H12\", \"H22\")])\n",
        "#G.add_edges_from([(\"H21\", \"Y\"), (\"H22\", \"Y\")])\n",
        "nx.draw(G, \n",
        "        nx.get_node_attributes(G, 'pos'), \n",
        "        with_labels=True, \n",
        "        font_weight='bold', \n",
        "        node_size = 1000,\n",
        "        node_color = \"lightblue\",\n",
        "        linewidths = 3)\n",
        "ax= plt.gca()\n",
        "ax.collections[0].set_edgecolor(\"#000000\")\n",
        "ax.set_xlim([-1, 16])\n",
        "ax.set_ylim([.5, 5.5])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GANs do something like the following. They generate data (H21 and H22\n",
        "above) using a random number generator. These are passed through the\n",
        "generator to obtain simulated records (H41-H48). These fake records\n",
        "are concatenated with real records to be passed through the\n",
        "discriminator, which tries to guess whether the records are real or\n",
        "fake. The two networks are trained adversarially. That is, the\n",
        "generator has higher loss when it fails to fool the discriminator and\n",
        "the discriminator has higher loss when it fails to discriminate\n",
        "between real and fake records.\n",
        "\n",
        "This sort of approach can be used for data of any type. But, it's fun\n",
        "especially to do it using images. Some of the images generated from\n",
        "GANs are wild in how realistic looking they are. Let's try to create a\n",
        "GAN to generate our cryptopunks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "import PIL\n",
        "\n",
        "\n",
        "## Read in and organize the data\n",
        "imgURL = \"https://raw.githubusercontent.com/larvalabs/cryptopunks/master/punks.png\"\n",
        "urllib.request.urlretrieve(imgURL, \"cryptoPunksAll.jpg\")\n",
        "img = PIL.Image.open(\"cryptoPunksAll.jpg\").convert(\"RGB\")\n",
        "imgArray = np.asarray(img)\n",
        "finalArray = np.empty((10000, 3, 24, 24))\n",
        "for i in range(100):\n",
        "  for j in range(100):\n",
        "    a, b = 24 * i, 24 * (i + 1)  \n",
        "    c, d = 24 * j, 24 * (j + 1) \n",
        "    idx = j + i * (100)\n",
        "    finalArray[idx,0,:,:] = imgArray[a:b,c:d,0]\n",
        "    finalArray[idx,1,:,:] = imgArray[a:b,c:d,1]\n",
        "    finalArray[idx,2,:,:] = imgArray[a:b,c:d,2]\n",
        "\n",
        "n = finalArray.shape[0]\n",
        "x_real = finalArray / 255\n",
        "x_real = torch.tensor(x_real.astype(np.float32))\n",
        "x_real.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the generator, we'll use a similar construction as the decoding\n",
        "layer from our autoencoder chapter. For the discriminator, let's use a\n",
        "similar network to the one we used in our convolutional NN chapter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Define our constants for our networks\n",
        "kernel_size = 5\n",
        "generator_input_dim = [16, 3, 3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class create_generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()        \n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(16, 128, 10, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 3, 4, 2, 1, bias=False), \n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        " \n",
        "## Use the discriminator from the convnet chapter\n",
        "class create_discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 12, 5)\n",
        "        self.fc1 = nn.Linear(12 * 3 * 3, 32)\n",
        "        self.fc2 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "    \n",
        "        \n",
        "generator = create_generator()\n",
        "discriminator = create_discriminator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's try out our generator. First, we're going to generate n\n",
        "embeddings. Then we'll feed them through the generator to obtain n\n",
        "images. Notice that they don't look so good. This is because we\n",
        "haven't trained out generator yet!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "test_embedding = torch.randn([5]+generator_input_dim)\n",
        "x_fake = generator(test_embedding)\n",
        "\n",
        "## Plot out the first 5 images, note this isn't very interesting, since\n",
        "## all of the weights haven't been trained\n",
        "plt.figure(figsize=(10,5))\n",
        "for i in range(5): \n",
        "  plt.subplot(1, 5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  img = np.transpose(x_fake.detach().numpy()[i,:,:,:], (1, 2, 0))\n",
        "  plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Our label convention, real_label = 1, fake_label = 0\n",
        "\n",
        "lr = 1e-4\n",
        "\n",
        "## y is n real images then n fake images\n",
        "y = torch.concat( (torch.ones(n), torch.zeros(n) ) ) \n",
        "\n",
        "## Set up optimizers\n",
        "optimizerD = optim.Adam(discriminator.parameters(), lr=lr)\n",
        "optimizerG = optim.Adam(generator.parameters(), lr=lr)\n",
        "\n",
        "## Set up the loss function\n",
        "loss_function = nn.BCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A couple of details. First, to speed up the algorithm, I'm using\n",
        "random batches of 100. You can do this directly with torch's\n",
        "dataloader, but I decided just to do it manually. Secondly, you have\n",
        "to run the algorithm for a long time. The code below just says 20,\n",
        "because that was the very last size I used. The results are of 4k\n",
        "epochs or so. Finally, note that we save the networks in progress and\n",
        "I wrote in some code that lets me restart the network with the saved\n",
        "states. So, if my program halts for any reason, I didn't lose all of\n",
        "its progress."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "randomBatchSize = .1\n",
        "n_epochs = 20\n",
        "trainFraction = .1\n",
        "\n",
        "for epoch in range(n_epochs):          \n",
        "    ## Generate the batch sample\n",
        "    sample = np.random.uniform(size = n) < trainFraction\n",
        "    n_batch = np.sum(sample)\n",
        "\n",
        "    ## Generate the simulated embedding    \n",
        "    embedding = torch.randn([n_batch]+generator_input_dim)\n",
        "    \n",
        "    \n",
        "    ## Generate new fake images\n",
        "    x_fake = generator(embedding)\n",
        "    \n",
        "    ## train the discriminator\n",
        "    ## zero out the gradient\n",
        "    discriminator.zero_grad()\n",
        "\n",
        "    ## run the generated and fake images through the discriminator\n",
        "    yhat_fake = discriminator(x_fake.detach())\n",
        "    yhat_real = discriminator(x_real[sample,:, :, :])\n",
        "    ## Note you have to concatenate them in the same order as \n",
        "    ## the previous cell. Remember we did real then fake\n",
        "    yhat = torch.concat( (yhat_real, yhat_fake) ).reshape(-1)\n",
        "\n",
        "    ## Calculate loss on all-real batch \n",
        "    y = torch.concat( (torch.ones(n_batch), torch.zeros(n_batch) ) ) \n",
        "\n",
        "    discriminator_error = loss_function(yhat, y)\n",
        "\n",
        "    # Calculate gradients for D in backward pass\n",
        "    discriminator_error.backward(retain_graph = True)\n",
        "\n",
        "    # Update the discriminator\n",
        "    optimizerD.step()\n",
        "\n",
        "    ## Train the generator\n",
        "    ## zero out the gradient\n",
        "    generator.zero_grad()\n",
        "    ## The discriminator has been udpated, so push the data through the \n",
        "    ## new discriminator\n",
        "    yhat_fake = discriminator(x_fake)\n",
        "    ## Note the outcome for the generator is all ones even\n",
        "    ## though we're classifying real as 1 and fake as 0\n",
        "    ## In other words, we want the loss for the generator to be\n",
        "    ## based on how real-like the generated data is\n",
        "    generator_error = loss_function( yhat_fake,  torch.ones( (n_batch, 1) ) )\n",
        "    ## Calculate the backwards error\n",
        "    generator_error.backward(retain_graph = False)\n",
        "    # Update the discriminator\n",
        "    optimizerG.step()\n",
        "    \n",
        "    if (epoch + 1) % 10 == 0:  \n",
        "        ## print(epoch, end = \",\")\n",
        "        ## Save the state dictionary in progress\n",
        "        torch.save(generator.state_dict(), \"generator.pt\")\n",
        "        torch.save(discriminator.state_dict(), \"discriminator.pt\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here's 25 of our generated punks. It's clearly getting there. Notice,\n",
        "some of the punks have an earring. Also, some have a slightly green\n",
        "tinge, presumably because of the green (zombie) punks in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25): \n",
        "  plt.subplot(5, 5,i+1)\n",
        "#  plt.xticks([])\n",
        "#  plt.yticks([])\n",
        "  img = np.transpose(x_fake.detach().numpy()[i,:,:,:], (1, 2, 0))\n",
        "  plt.imshow(img)  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}