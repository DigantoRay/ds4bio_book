{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Autoencoder example\n",
        "\n",
        "Autoencoders are another unsupervised learning technique. Autoencoders\n",
        "take in a record and spit out a prediction of the same size. The goal\n",
        "is to represent the records as a NN. In an incomplete autoencoder, the\n",
        "model is regularized by the embedding (middle) layer being much lower\n",
        "than the input dimension. In this way, an autoencoder is a dimension\n",
        "reduction technique, reducing the input dimension size downto a much\n",
        "lower size (the encoder) then back out to the original size (the\n",
        "decoder). We can represent the autoencoder with a network diagram as\n",
        "below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sklearn as skl\n",
        "\n",
        "#plt.figure(figsize=[2, 2])\n",
        "G = nx.DiGraph()\n",
        "G.add_node(\"X1\",  pos = (0, 5) )\n",
        "G.add_node(\"X2\",  pos = (1, 5) )\n",
        "G.add_node(\"X3\",  pos = (2, 5) )\n",
        "G.add_node(\"X4\",  pos = (3, 5) )\n",
        "G.add_node(\"X5\",  pos = (4, 5) )\n",
        "G.add_node(\"X6\",  pos = (5, 5) )\n",
        "G.add_node(\"X7\",  pos = (6, 5) )\n",
        "G.add_node(\"X8\",  pos = (7, 5) )\n",
        "\n",
        "G.add_node(\"H11\",  pos = (1.4, 4) )\n",
        "G.add_node(\"H12\",  pos = (2.8, 4) )\n",
        "G.add_node(\"H13\",  pos = (4.2, 4) )\n",
        "G.add_node(\"H14\",  pos = (5.6, 4) )\n",
        "\n",
        "G.add_node(\"H21\",  pos = (2.1, 3) )\n",
        "G.add_node(\"H22\",  pos = (4.9, 3) )\n",
        "\n",
        "G.add_node(\"H31\",  pos = (1.4, 2) )\n",
        "G.add_node(\"H32\",  pos = (2.8, 2) )\n",
        "G.add_node(\"H33\",  pos = (4.2, 2) )\n",
        "G.add_node(\"H34\",  pos = (5.6, 2) )\n",
        "\n",
        "\n",
        "G.add_node(\"H41\",  pos = (0, 1) )\n",
        "G.add_node(\"H42\",  pos = (1, 1) )\n",
        "G.add_node(\"H43\",  pos = (2, 1) )\n",
        "G.add_node(\"H44\",  pos = (3, 1) )\n",
        "G.add_node(\"H45\",  pos = (4, 1) )\n",
        "G.add_node(\"H46\",  pos = (5, 1) )\n",
        "G.add_node(\"H47\",  pos = (6, 1) )\n",
        "G.add_node(\"H48\",  pos = (7, 1) )\n",
        "\n",
        "G.add_edges_from([ (\"X1\", \"H11\"),  (\"X1\", \"H12\"),  (\"X1\", \"H13\"),  (\"X1\", \"H14\")])\n",
        "G.add_edges_from([ (\"X2\", \"H11\"),  (\"X2\", \"H12\"),  (\"X2\", \"H13\"),  (\"X2\", \"H14\")])\n",
        "G.add_edges_from([ (\"X3\", \"H11\"),  (\"X3\", \"H12\"),  (\"X3\", \"H13\"),  (\"X3\", \"H14\")])\n",
        "G.add_edges_from([ (\"X4\", \"H11\"),  (\"X4\", \"H12\"),  (\"X4\", \"H13\"),  (\"X4\", \"H14\")])\n",
        "G.add_edges_from([ (\"X5\", \"H11\"),  (\"X5\", \"H12\"),  (\"X5\", \"H13\"),  (\"X5\", \"H14\")])\n",
        "G.add_edges_from([ (\"X6\", \"H11\"),  (\"X6\", \"H12\"),  (\"X6\", \"H13\"),  (\"X6\", \"H14\")])\n",
        "G.add_edges_from([ (\"X7\", \"H11\"),  (\"X7\", \"H12\"),  (\"X7\", \"H13\"),  (\"X7\", \"H14\")])\n",
        "G.add_edges_from([ (\"X8\", \"H11\"),  (\"X8\", \"H12\"),  (\"X8\", \"H13\"),  (\"X8\", \"H14\")])\n",
        "\n",
        "G.add_edges_from([ (\"H11\", \"H21\"),  (\"H11\", \"H22\")])\n",
        "G.add_edges_from([ (\"H12\", \"H21\"),  (\"H12\", \"H22\")])\n",
        "G.add_edges_from([ (\"H13\", \"H21\"),  (\"H13\", \"H22\")])\n",
        "G.add_edges_from([ (\"H14\", \"H21\"),  (\"H14\", \"H22\")])\n",
        "\n",
        "\n",
        "G.add_edges_from([ (\"H21\", \"H31\"),  (\"H21\", \"H32\"),  (\"H21\", \"H33\"),  (\"H21\", \"H34\")])\n",
        "G.add_edges_from([ (\"H22\", \"H31\"),  (\"H22\", \"H32\"),  (\"H22\", \"H33\"),  (\"H22\", \"H34\")])\n",
        "\n",
        "G.add_edges_from([ (\"H31\", \"H41\"),  (\"H31\", \"H42\"),  (\"H31\", \"H43\"),  (\"H31\", \"H44\")])\n",
        "G.add_edges_from([ (\"H31\", \"H45\"),  (\"H31\", \"H46\"),  (\"H31\", \"H47\"),  (\"H31\", \"H48\")])\n",
        "G.add_edges_from([ (\"H32\", \"H41\"),  (\"H32\", \"H42\"),  (\"H32\", \"H43\"),  (\"H32\", \"H44\")])\n",
        "G.add_edges_from([ (\"H32\", \"H45\"),  (\"H32\", \"H46\"),  (\"H32\", \"H47\"),  (\"H32\", \"H48\")])\n",
        "G.add_edges_from([ (\"H33\", \"H41\"),  (\"H33\", \"H42\"),  (\"H33\", \"H43\"),  (\"H33\", \"H44\")])\n",
        "G.add_edges_from([ (\"H33\", \"H45\"),  (\"H33\", \"H46\"),  (\"H33\", \"H47\"),  (\"H33\", \"H48\")])\n",
        "G.add_edges_from([ (\"H34\", \"H41\"),  (\"H34\", \"H42\"),  (\"H34\", \"H43\"),  (\"H34\", \"H44\")])\n",
        "G.add_edges_from([ (\"H34\", \"H45\"),  (\"H34\", \"H46\"),  (\"H34\", \"H47\"),  (\"H34\", \"H48\")])\n",
        "\n",
        "\n",
        "#G.add_edges_from([(\"H11\", \"H21\"), (\"H11\", \"H22\"), (\"H12\", \"H21\"), (\"H12\", \"H22\")])\n",
        "#G.add_edges_from([(\"H21\", \"Y\"), (\"H22\", \"Y\")])\n",
        "nx.draw(G, \n",
        "        nx.get_node_attributes(G, 'pos'), \n",
        "        with_labels=True, \n",
        "        font_weight='bold', \n",
        "        node_size = 1000,\n",
        "        node_color = \"lightblue\",\n",
        "        linewidths = 3)\n",
        "ax= plt.gca()\n",
        "ax.collections[0].set_edgecolor(\"#000000\")\n",
        "ax.set_xlim([-.5, 7.5])\n",
        "ax.set_ylim([.5, 5.5])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let $\\phi$ be the first two layers of the network and $\\theta$ be the\n",
        "last two. So, if we wanted to pass a data row, $x_i$ through the\n",
        "network we would do $\\theta(\\phi(x_i))$. We would call the network\n",
        "$\\phi$ as the *encoding* network and $\\theta$ as the decoding\n",
        "network. Consider training the network by minimizing\n",
        "\n",
        "$$\n",
        "\\sum_{i=1}^n || x_i - \\theta(\\phi(x_i)) ||^2\n",
        "$$\n",
        "\n",
        "over the weights. This sort of network is called an\n",
        "autoencoder. Notice that the same data is the input and output of the\n",
        "network. This kind of learning is called **unsupervised**, since we're\n",
        "not trying to use $x$ to predict an outcome $y$. Instead, we're trying\n",
        "to explore variation and find interesting features in $x$ as a goal in\n",
        "itself without a \"supervising\" outcome, $y$, to help out.\n",
        "\n",
        "Notice overfitting concerns are somewhat different in this network\n",
        "construction. If this model fits well, then it's suggesting that 2\n",
        "numbers can explain 8. That is, the network will have reduced the\n",
        "inputs to only two dimensions, that we could visualize for\n",
        "example. That is a form of parsimony that prevents overfitting. The\n",
        "middle layer is called the embedding. It is called this because an\n",
        "autoencoder is a form of non-linear embedding of our data into a lower\n",
        "dimensionional space.\n",
        "\n",
        "There's nothing to prevent us from having convolutional layers if the\n",
        "inputs are images. That's what we'll work on here. For convolutional\n",
        "autoencoders, it's typical to increase the number of channels and\n",
        "decrease the image sizes as one works through the network.\n",
        "\n",
        "### PCA and autoencoders\n",
        "\n",
        "Without modification, autoencoders can be programmed that span the\n",
        "same space as PCA/SVD [@plaut2018principal]. Enforcing the\n",
        "orthogonality requires something like adding Lagrange terms to the\n",
        "loss function. There's no reason why you would do this, since PCA is\n",
        "well developed and works just fine. However, it does suggest why NNs\n",
        "are such a large class of models.\n",
        "\n",
        "Let $X_i$ be a collection of features for record $i$. Then, the SVD\n",
        "approximates the data matrix $X$ with $UV^t$, where we've absorbed the\n",
        "singular values into either $U$ or $V$. Per record, this model for $K$\n",
        "components and column $k$ from $V$ of $v_k$.\n",
        "\n",
        "$$\n",
        "\\hat x_i = \\sum_{k=1}^K <x_i, v_k> v_k \n",
        "$$\n",
        "\n",
        "Therefore, consider a neural network that specifies that the first layer defines $K$ hidden units as \n",
        "\n",
        "$$\n",
        "h_{ik} = <x_i, v_k>.\n",
        "$$\n",
        "\n",
        "That is, it has a linear activation function with no bias term and weights $v_{jk}$ where $v_{jk}$ is element $j$ of vector $v_k$. Then consider an output layer that defines\n",
        "\n",
        "$$\n",
        "\\hat x_{ij} = \\sum_{k=1}^K h_{ik} v_{jk},\n",
        "$$\n",
        "\n",
        "Again, this is a linear activation function with weights $v_{jk}$. So,\n",
        "we arrive at the conclusion, that PCA is an example of an autoencoder\n",
        "with two layers, constraints on the weights being common to both\n",
        "layers, and constraints on the loss function that enforces the\n",
        "orthonormality of the $v_k$. Of course, as we saw with ordinary\n",
        "regression, whether or not we can actually get gradient descent to\n",
        "converge remains a harder issue than just using PCA\n",
        "directly. Furthermore, the autoencoder wouldn't necessarily order the\n",
        "PCs similarly.\n",
        "\n",
        "Finally, we see that a two layer autoencoder -without the constraints-\n",
        "contains the PCA fit as a special case and spans the same space as the\n",
        "PCA fit. Similarly we see that such a two layer encoder is\n",
        "overspecified, as most NNs are.\n",
        "\n",
        "### Example on dermamnist\n",
        "\n",
        "First, let's set up our autoencoder  by defining a python class then initializing it.\n",
        "We assume the imports and data loading from the chapter on PCA and ICA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy.linalg as la\n",
        "from sklearn.decomposition import PCA\n",
        "import urllib.request\n",
        "import PIL\n",
        "import numpy as np\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.decomposition import FastICA\n",
        "from tqdm import tqdm\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "import scipy\n",
        "import IPython"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "data_flag = 'dermamnist'\n",
        "\n",
        "## This defines our NN parameters\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "lr = 0.001\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "##https://github.com/MedMNIST/MedMNIST/blob/main/examples/getting_started.ipynb\n",
        "data_flag = 'dermamnist'\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "  \n",
        "  transforms.ToTensor()\n",
        "\n",
        "])\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(split = 'train', transform = data_transform, download = True)\n",
        "test_dataset  = DataClass(split = 'test' , transform = data_transform, download = True)\n",
        "pil_dataset   = DataClass(split = 'train',                             download = True)\n",
        "\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "\n",
        "def loader_to_array(dataloader):\n",
        "  ## Read one iteration to get data\n",
        "  test_input, test_target = next(iter(dataloader))\n",
        "  ## Total number of training images\n",
        "  n = np.sum([inputs.shape[0] for inputs, targets in dataloader])\n",
        "  ## The dimensions of the images\n",
        "  imgdim = (test_input.shape[2], test_input.shape[3])\n",
        "  images = np.empty( (n, imgdim[0], imgdim[1], 3))\n",
        "\n",
        "  ## Read the data from the data loader into our numpy array\n",
        "  idx = 0\n",
        "  for inputs, targets in dataloader:\n",
        "    inputs = inputs.detach().numpy()\n",
        "    for j in range(inputs.shape[0]):\n",
        "      img = inputs[j,:,:,:]\n",
        "      ## get it out of pytorch format\n",
        "      img = np.transpose(img, (1, 2, 0))\n",
        "      images[idx,:,:,:] = img\n",
        "      matrix = images.reshape(n, 3 * np.prod(imgdim))\n",
        "      idx += 1\n",
        "  return images, matrix\n",
        "\n",
        "train_images, train_matrix = loader_to_array(train_loader)\n",
        "test_images, test_matrix = loader_to_array(test_loader)\n",
        "\n",
        "## Demean the matrices\n",
        "train_mean = train_matrix.mean(0)\n",
        "train_matrix = train_matrix - train_mean\n",
        "test_mean = test_matrix.mean(0)\n",
        "test_matrix = test_matrix - test_mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "kernel_size = 5\n",
        "\n",
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, 6, kernel_size)\n",
        "        self.conv2 = nn.Conv2d(6, 12, kernel_size)\n",
        "        self.pool  = nn.MaxPool2d(2, 2)\n",
        "        self.iconv1 = nn.ConvTranspose2d(12, 6, kernel_size+1, stride = 2)\n",
        "        self.iconv2 = nn.ConvTranspose2d(6, 3, kernel_size+1, stride = 2)\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        return x\n",
        "    \n",
        "    def decode(self, x):\n",
        "        x = F.relu(self.iconv1(x))\n",
        "        ## Use the sigmoid as the final layer \n",
        "        ## since we've normalized pixel values to be between 0 and 1\n",
        "        x = torch.sigmoid(self.iconv2(x))\n",
        "        return(x)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.decode(self.encode(x))\n",
        "    \n",
        "autoencoder = autoencoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can try out the autoencoder by "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Here's some example data by grabbing one batch\n",
        "tryItOut, _ = next(iter(train_loader))\n",
        "print(tryItOut.shape)\n",
        "\n",
        "## Let's encode that data\n",
        "encoded = autoencoder.encode(tryItOut)\n",
        "print(encoded.shape)\n",
        "\n",
        "## Now let's decode the encoded data\n",
        "decoded = autoencoder.decode(encoded)\n",
        "print(decoded.shape)\n",
        "\n",
        "## Now let's run the whole thing through\n",
        "fedForward = autoencoder.forward(tryItOut)\n",
        "print(fedForward.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "test = fedForward.detach().numpy()\n",
        "\n",
        "## Plot out the first 5 images, note this isn't very interesting, since\n",
        "## all of the weights haven't been trained\n",
        "plt.figure(figsize=(10,5))\n",
        "for i in range(5): \n",
        "  plt.subplot(1, 5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  img = np.transpose(test[i,:,:,:], (1, 2, 0))\n",
        "  plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Optimizer\n",
        "optimizer = torch.optim.Adam(autoencoder.parameters(), lr = 0.001)\n",
        "\n",
        "#Epochs\n",
        "n_epochs = 20\n",
        "\n",
        "autoencoder.train()\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for data, _ in train_loader:\n",
        "        images = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = autoencoder.forward(images)\n",
        "        loss = F.mse_loss(outputs, images)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## the data from the last iteration is called images\n",
        "trainSample = images.detach().numpy()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "for i in range(5): \n",
        "  plt.subplot(1, 5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  img = np.transpose(trainSample[i,:,:,:], (1, 2, 0))\n",
        "  plt.imshow(img)\n",
        "\n",
        "## the output from the last iterations (feed forward through the network) is called outputs\n",
        "trainOutput = outputs.detach().numpy()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "for i in range(5): \n",
        "  plt.subplot(2, 5,i+6)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  img = np.transpose(trainOutput[i,:,:,:], (1, 2, 0))\n",
        "  plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On a test batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "test_batch, _ = next(iter(test_loader))\n",
        "x_test = test_batch.detach().numpy()\n",
        "testSample = autoencoder.forward(test_batch).detach().numpy()\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "\n",
        "## Plot the original data\n",
        "for i in range(5): \n",
        "  plt.subplot(2, 5, i + 1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  img = np.transpose(x_test[i,:,:,:], (1, 2, 0))\n",
        "  plt.imshow(img)\n",
        "# Plot the data having been run throught the convolutional autoencoder\n",
        "for i in range(5): \n",
        "  plt.subplot(2, 5, i + 6)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  img = np.transpose(testSample[i,:,:,:], (1, 2, 0))\n",
        "  plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}