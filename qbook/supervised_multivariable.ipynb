{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Linear separable models \n",
        "\n",
        "We've now covered two ways to do prediction with a single variable,\n",
        "classification using logistic regression and prediction using a line\n",
        "and least squares. What if we have several predictiors?\n",
        "\n",
        "In both the logistic and linear regression models, we had a linear\n",
        "predictor, specifically,\n",
        "\n",
        "$$\n",
        "\\eta_i = \\beta_0 + \\beta_1 x_i.\n",
        "$$\n",
        "\n",
        "In the continuous case, we were modeling the expected value of the\n",
        "outcomes as linear. In the binary case, we were assuming that the\n",
        "naturual logarithm of the odds of a 1 outcome was linear.\n",
        "\n",
        "To estimate the unknown parameters, $\\beta_0$ and $\\beta_1$ we minimized\n",
        "\n",
        "$$\n",
        "\\sum_{i=1}^n || y_i - \\eta_i||^2 \n",
        "$$\n",
        "\n",
        "in the linear case and \n",
        "\n",
        "$$\n",
        "-\\sum_{i=1}^n \\left[\n",
        "  Y_i \\eta_i + \\log\\left\\{\\frac{1}{1 + e^{\\eta_i}} \\right\\} \\right].\n",
        "$$\n",
        "\n",
        "in the binary outcome case (where, recall, $\\eta_i$ depends on the\n",
        "parameters).  We can easily extend these models to multiple predictors\n",
        "by assuming that the impact of the multiple predictors is linear and\n",
        "separable. That is,\n",
        "\n",
        "$$\n",
        "\\eta_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\ldots \\beta_{p-1} x_{p-1,i}\n",
        "$$\n",
        "\n",
        "If we think about this as vectors and matrices, we obtain\n",
        "\n",
        "$$\n",
        "\\eta = X \\beta\n",
        "$$\n",
        "\n",
        "where $\\eta$ is an $n \\times 1$ vector, $X$ is an $n \\times p$ matrix\n",
        "with $i,j$ entry $x_{ij}$ and $\\beta$ is a $p\\times 1$ vector with\n",
        "entries $\\beta_j$.\n",
        "\n",
        "Let's look at the voxel-level data that we've been working with. First\n",
        "let's load the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.linear_model as lm\n",
        "import sklearn as skl\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels as sm\n",
        "\n",
        "## this sets some style parameters  \n",
        "sns.set()\n",
        "\n",
        "## Read in the data \n",
        "dat = pd.read_csv(\"https://raw.githubusercontent.com/bcaffo/ds4bme_intro/master/data/oasis.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's first try to fit the proton density data from the other imaging\n",
        "data. I'm going to use the `statsmodels` version of linear models\n",
        "since it has a nice format for dataframes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "trainFraction = .75\n",
        "sample = np.random.uniform(size = 100) < trainFraction\n",
        "trainingDat = dat[sample]\n",
        "testingDat = dat[~sample]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "results = smf.ols('PD ~ FLAIR + T1 + T2  + FLAIR_10 + T1_10 + T2_10 + FLAIR_20', data = trainingDat).fit()\n",
        "print(results.summary2())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x = dat[['FLAIR','T1', 'T2', 'FLAIR_10', 'T1_10', 'T2_10', 'FLAIR_20']]\n",
        "y = dat[['GOLD_Lesions']]\n",
        "## Add the intercept column\n",
        "x = sm.tools.add_constant(x)\n",
        "\n",
        "xtraining = x[sample]\n",
        "xtesting = x[~sample]\n",
        "ytraining = y[sample]\n",
        "ytesting = y[~sample]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit = sm.discrete.discrete_model.Logit(ytraining, xtraining).fit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's evaluate our prediction. Here, we're not going to classify\n",
        "as 0 or 1, but rather estimate the prediction. Note, we then would\n",
        "need to pick a threshold to have a classifier. We could use .5 as our\n",
        "threshold. However, it's often the case that we don't necessarily want\n",
        "to threshold at specifically that level. A solution for evalution is\n",
        "to plot how the sensitivity and specificity change by the threshold.\n",
        "\n",
        "In other words, consider the triplets\n",
        "$$\n",
        "(t, sens(t), spec(t))\n",
        "$$\n",
        "where $t$ is the threshold, `sens(t)` is the sensitivity at threshold $t$, `spec(t)` is the specificity at threshold `t`. \n",
        "\n",
        "Necessarily, the sensitivity and specificity \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "phatTesting = fit.predict(xtesting)\n",
        "\n",
        "## See here for plotting\n",
        "## https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python\n",
        "fpr, tpr, threshold = skl.metrics.roc_curve(ytesting, phatTesting)\n",
        "roc_auc = skl.metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aside different python packages\n",
        "\n",
        "So far we've explored several plotting libraries including: default\n",
        "pandas methods, matplotlib, seaborn and plotly. We've also looked at\n",
        "several fitting libraries including to some extent numpy, but\n",
        "especially scikitlearn and statsmodels. What's the difference? Well,\n",
        "these packages are all mantained by different people and have\n",
        "different features and goals. For example, scikitlearn is more\n",
        "expansive than statsmodels, but statsmodels functions more like one is\n",
        "used to with statistical output. Matplotlib is very expansive, but\n",
        "seaborn has nicer default options and is a little easier. So, when\n",
        "doing data science with python, one has to get used to trying out a\n",
        "few packages, weighing the cost and benefits of each, and picking one.\n",
        "\n",
        "'statsmodels', what we're using above, has multiple methods for\n",
        "fitting binary models including: `sm.Logit`, `smf.logit`,\n",
        "`BinaryModel` and `glm`. Here I'm just going to use `Logit` which does\n",
        "not use the formula syntax of `logit`. Note, by default, this does not\n",
        "add an intercept this way. So, I'm adding a column of ones, which adds\n",
        "an intercept.\n",
        "\n",
        "Consider the following which uses the formula API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "results = smf.logit(formula = 'GOLD_Lesions ~ FLAIR + T1 + T2 + FLAIR_10 + T1_10 + T2_10 + FLAIR_20', data = trainingDat).fit()\n",
        "results.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A classic example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dat = pd.read_csv(\"https://raw.githubusercontent.com/bcaffo/ds4bme_intro/master/data/swiss.csv\")\n",
        "dat.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y = dat.Fertility\n",
        "x = dat.drop(['Region', 'Fertility'], axis=1)\n",
        "fit = LinearRegression().fit(x, y)\n",
        "yhat = fit.predict(x)\n",
        "[fit.intercept_, fit.coef_]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x2 = x\n",
        "x2['Test'] = x2.Agriculture + x2.Examination\n",
        "fit2 = LinearRegression().fit(x2, y)\n",
        "yhat2 = fit2.predict(x2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(yhat, yhat2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x3 = x2.drop(['Agriculture'], axis = 1)\n",
        "fit3 = LinearRegression().fit(x3, y)\n",
        "yhat3 = fit3.predict(x3)\n",
        "plt.plot(yhat, yhat3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regression interpretation\n",
        "\n",
        "Let's consider how adjustment works in regression by considering a so\n",
        "called ANCOVA (analysis of covariance) setting. Imagine, there's\n",
        "treatment variable that we're ineterested in, $T_i$, and a regression\n",
        "variable that we have to adjust for, $X_i$. Consider this specific\n",
        "variation of this setting:\n",
        "\n",
        "$$\n",
        "Y_i = \\beta_0 + \\beta_1 X_i + \\beta_2 T_i + \\epsilon_i\n",
        "$$\n",
        "\n",
        "To tie ourselves down with a context, consider $Y_i$ is blood\n",
        "pressure, $T_i$ is a medication and $X_i$ is BMI. Let's look at\n",
        "different settings that could arise using plots.\n",
        "\n",
        "Since I'm going to be making the same plot over and over, I defined a function that\n",
        "\n",
        "1. fit the ANCOVA model using sklearn\n",
        "2. plotted the data as $X$ versus $Y$ with orange versus blue for treated versus not\n",
        "3. added the fitted ANCOVA lines plus the marginal means (the means for each group disregarding $X$) as horizontal lines\n",
        "\n",
        "Note, the adjusted estimated treatment effect is the difference\n",
        "between the two parallel sloped lines. The unadjusted estimated\n",
        "treatment effect is the difference between the two horizontal\n",
        "lines. Let's look at how adjustment changes things depending on the\n",
        "setting. First we'll do our imports and then define a function that\n",
        "will make our plot for us and fit the ANCOVA model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import copy\n",
        "\n",
        "sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def myplot(x, y, t):\n",
        "    x1 = x[t == 1]\n",
        "    x0 = x[t == 0]\n",
        "    y1 = y[t == 1]\n",
        "    y0 = y[t == 0]\n",
        "    xm1 = np.mean(x1)\n",
        "    xm0 = np.mean(x0)\n",
        "    ym1 = np.mean(y1)\n",
        "    ym0 = np.mean(y0)\n",
        "\n",
        "    X = np.array([x, t]).transpose()\n",
        "    out = LinearRegression().fit(X, y)\n",
        "    b0hat = out.intercept_\n",
        "    b1hat = out.coef_[0]\n",
        "    b2hat = out.coef_[1]\n",
        "    \n",
        "    plt.scatter(x0, y0)\n",
        "    plt.scatter(x1, y1)\n",
        "\n",
        "    col = sns.color_palette()\n",
        "\n",
        "    plt.axhline(y = ym0, c = col[0])\n",
        "    plt.axhline(y = ym1, c = col[1])\n",
        "\n",
        "    xlim = [np.min(x), np.max(x)]\n",
        "\n",
        "    ylim0 = [z * b1hat + b0hat + b2hat for z in xlim]\n",
        "    ylim1 = [z * b1hat + b0hat         for z in xlim]\n",
        "\n",
        "    plt.plot( xlim, ylim1)\n",
        "    plt.plot( xlim, ylim0) \n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's consider out model with $\\beta_0 = 0$, $\\beta_1 = 1$ and\n",
        "$\\beta_2 = 4$. So the treated have an intercept 4 units higher. Let's\n",
        "consider simulating from this model where the treatment is randomized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n = 100\n",
        "x = np.random.normal(size = n)\n",
        "e = np.random.normal(size = n)\n",
        "t = np.random.binomial(1, .5, n)\n",
        "\n",
        "beta0 = 0\n",
        "beta1 = 1\n",
        "beta2 = 4\n",
        "\n",
        "y = beta0 + beta1 * x + beta2 * t + e\n",
        "\n",
        "myplot(x, y, t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that the marginal means (horizontal lines) are about 4 units\n",
        "appart, same as the lines. This is due to the randomization. A goal of\n",
        "randomization is to make our inference for the treatment unrelated to\n",
        "whether or not we adjust for the confounding variable ($X$). So, we\n",
        "get (up to random error) the ssame answer whether we adjust for $X$ or\n",
        "not. Let's consider a different setting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "myplot(x + t * 4, y, t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now notice that there is a large unadjusted difference (difference\n",
        "between the horizontal lines) whereas there is not much of a\n",
        "difference between the lines. That is, when adjusting for $X$, the\n",
        "relationship goes away. Of note, treatment assignment is highly\n",
        "related to the $X$ variable. Orange dots tend to have a larger $X$\n",
        "value than the blue. Because of this, there's pratically no area of\n",
        "overlap between the orange and the blue to directly compare them. The\n",
        "adjusted model is all model, extrapolating the blue line up to the\n",
        "orange and the orange down to the blue assuming that they're parallel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "myplot(x + t * 4, y  - t * 4, t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Above notice that the result is the reverse. There's little\n",
        "association marginally, but a large one when conditioning. Let's look\n",
        "at one final case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "myplot(x + t * 6, y  - t * 2, t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Above things are even worse, the relationship has reversed itself. The\n",
        "marginal association is that the orange is above the blue whereas the\n",
        "conditional association is that the blue is above the orange. That is,\n",
        "if you fit the treatment model without $X$ you get one answer, and\n",
        "with $X$ you get the exact opposite answer! This is an example of\n",
        "so-called \"Simpsons paradox\". The \"paradox\" isn't that paradoxical. It\n",
        "simply says the relationship between two variables could reverse\n",
        "itself when factoring in another variable. Once again, note there's no\n",
        "overlap in the distributions.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}