{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Logistic regression as a NN\n",
        "\n",
        "This is an extension of using pytorch to perform linear regression to\n",
        "using it to perform logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels as sm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "## Read in the data and display a few rows\n",
        "dat = pd.read_csv(\"https://raw.githubusercontent.com/bcaffo/ds4bme_intro/master/data/oasis.csv\")\n",
        "dat.head(4)\n",
        "\n",
        "## Create a binary outcome variable (people will use gold lesions in HW)\n",
        "m = np.median(dat.T2)\n",
        "dat = dat.assign(y = (dat.T2 > m) * 1 )\n",
        "## Create a normalized regression variable\n",
        "dat = dat.assign(x = (dat.PD - np.mean(dat.PD)) / np.std(dat.PD))\n",
        "dat.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit = smf.logit('y ~ x', data = dat).fit()\n",
        "fit.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# The in sample predictions\n",
        "yhat = 1 / (1 + np.exp(-fit.fittedvalues))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n = dat.shape[0]\n",
        "\n",
        "## Get the y and x from \n",
        "xtraining = torch.from_numpy(dat['x'].values)\n",
        "ytraining = torch.from_numpy(dat['y'].values)\n",
        "\n",
        "## PT wants floats\n",
        "xtraining = xtraining.float()\n",
        "ytraining = ytraining.float()\n",
        "\n",
        "## Dimension is 1xn not nx1\n",
        "## squeeze the second dimension\n",
        "xtraining = xtraining.unsqueeze(1)\n",
        "ytraining = ytraining.unsqueeze(1)\n",
        "\n",
        "## Show that everything is the right size\n",
        "[xtraining.shape, \n",
        " ytraining.shape,\n",
        " [n, 1]\n",
        " ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Doing it more now the pytorch docs recommend\n",
        "## Example taken from \n",
        "## https://medium.com/biaslyai/pytorch-linear-and-logistic-regression-models-5c5f0da2cb9\n",
        "\n",
        "## They recommend creating a class that defines\n",
        "## the model\n",
        "class LogisticRegression(torch.nn.Module):\n",
        "     def __init__(self):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(1, 1, bias = True)\n",
        "     def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "## Then the model is simply  \n",
        "model = LogisticRegression()\n",
        "\n",
        "## MSE is the loss function\n",
        "loss_fn = torch.nn.BCELoss()  \n",
        "\n",
        "## Set the optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
        "\n",
        "## Loop over iterations\n",
        "for t in range(100000):\n",
        "\n",
        "  ## Forward propagation\n",
        "  y_pred = model(xtraining)\n",
        "\n",
        "  ## the loss for this interation\n",
        "  loss = loss_fn(y_pred, ytraining)\n",
        "\n",
        "  #print(t, loss.item() / n)\n",
        "\n",
        "  ## Zero out the gradients before adding them up \n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  ## Backprop\n",
        "  loss.backward()\n",
        "  \n",
        "  ## Optimization step\n",
        "  optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ytest = model(xtraining)\n",
        "ytest = ytest.detach().numpy().reshape(-1)\n",
        "plt.plot(yhat, ytest,  \".\")\n",
        "plt.plot([0, 1], [0, 1], linewidth=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for param in model.parameters():  \n",
        "  print(param.data)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}