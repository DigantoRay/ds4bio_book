{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Explainability\n",
        "\n",
        "Explainability is an important aspect for building trust in a neural\n",
        "network. If you can't explain why your algorithm performs as it does,\n",
        "then at the very least there is concern for overfitting, or fitting on\n",
        "irrelevant features having and association with the outcome. Below\n",
        "we'll show a very basic version of explainability. Let's redo our\n",
        "convnet example, now on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import urllib.request\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "\n",
        "imgURL = \"https://raw.githubusercontent.com/larvalabs/cryptopunks/master/punks.png\"\n",
        "urllib.request.urlretrieve(imgURL, \"cryptoPunksAll.jpg\")\n",
        "img = PIL.Image.open(\"cryptoPunksAll.jpg\").convert(\"RGB\")\n",
        "imgArray = np.asarray(img)\n",
        "\n",
        "finalArray = np.empty((10000, 3, 24, 24))\n",
        "for i in range(100):\n",
        "  for j in range(100):\n",
        "    a, b = 24 * i, 24 * (i + 1)  \n",
        "    c, d = 24 * j, 24 * (j + 1) \n",
        "    idx = j + i * (100)\n",
        "    finalArray[idx,0,:,:] = imgArray[a:b,c:d,0]\n",
        "    finalArray[idx,1,:,:] = imgArray[a:b,c:d,1]\n",
        "    finalArray[idx,2,:,:] = imgArray[a:b,c:d,2]\n",
        "\n",
        "baseUrl = \"https://raw.githubusercontent.com/cryptopunksnotdead/punks.attributes/master/original/\"\n",
        "for i in range(0,10000, 1000):\n",
        "  url = baseUrl+str(i)+\"-\"+str(i + 999)+\".csv\"\n",
        "  print(url)\n",
        "  if (i == 0):\n",
        "    dat = pd.read_csv(url)\n",
        "  else :\n",
        "    dat = pd.concat ([dat, pd.read_csv(url)], \n",
        "                      join = 'inner',\n",
        "                     ignore_index = True)\n",
        "    \n",
        "\n",
        "dat = dat.assign(earring = dat[' accessories'].str.contains('Earring').astype(float).to_list())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else :\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "n = finalArray.shape[0]\n",
        "trainFraction = .75\n",
        "sample = np.random.uniform(size = n) < trainFraction\n",
        "x_train = finalArray[ sample, :, :, :] / 255\n",
        "x_test =  finalArray[~sample, :, :, :] / 255\n",
        "    \n",
        "y_train = dat.earring[sample].to_numpy()\n",
        "y_test =  dat.earring[~sample].to_numpy()\n",
        "## Need to have the extra dimension\n",
        "y_train = y_train.reshape(y_train.shape[0], 1)\n",
        "y_test = y_test.reshape(y_test.shape[0], 1)\n",
        "\n",
        "y_train = torch.Tensor(y_train).to(device)\n",
        "x_train = torch.Tensor(x_train).to(device)\n",
        "trainDataset = TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))\n",
        "trainloader = torch.utils.data.DataLoader(trainDataset, batch_size = 100, shuffle = False, num_workers = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 3 * 3, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        return x\n",
        "net = Net().to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for epoch in range(100):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here's the subject with the highest probability of having an\n",
        "earring. Let's save that subject and see what the algorithm finds so\n",
        "compelling about this subject."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "yhat = outputs.to( torch.device(\"cpu\") ).detach().numpy()\n",
        "## Grab the image that most likely has an earring\n",
        "idx = np.argmax(yhat)\n",
        "image = inputs.to( torch.device(\"cpu\")).detach().numpy()[idx, :, :, :]\n",
        "plt.imshow( np.transpose(image , (1, 2, 0)) )\n",
        "plt.xticks([])\n",
        "plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's take the image and, one pixel at a time, zero it out. Then that\n",
        "pixel's won't propigate through the network. Let's then take that\n",
        "image and feed it through the network. If that pixel was very\n",
        "important, then the prediction would drop. If it wasn't very\n",
        "important, the prediction would stay the same.\n",
        "\n",
        "To elaborate, let $I1$ be the one with the highest probability of\n",
        "having an earring. Then set $I2 = I1$ except $I2[i,j] = 0$ for some\n",
        "fixed $i$ and $j$. Let $P$ be an array of the same size and set\n",
        "$P[i,j] = \\phi(I2)$ where $\\phi$ is our convolutional network. Pixels\n",
        "where $P$ is low means the prediction dropped after the removal of\n",
        "that pixel.\n",
        "\n",
        "Let's try this out on this subject."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "xdim = image.shape[1]\n",
        "ydim = image.shape[2]\n",
        "probmap = np.empty([xdim, ydim])\n",
        "net.to(torch.device(\"cpu\"))\n",
        "for i in range(xdim):\n",
        "  for j in range(ydim):\n",
        "    temp = image.copy()\n",
        "    temp[0, i, j] = 0\n",
        "    temp[1, i, j] = 0\n",
        "    temp[2, i, j] = 0\n",
        "    ## add an extra row\n",
        "    temp = temp[np.newaxis, :, :, :]\n",
        "    probmap[i,j] = net(torch.tensor(temp))\n",
        "probmap.shape\n",
        "plt.imshow( probmap );\n",
        "plt.xticks([]);\n",
        "plt.yticks([]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that the probability that this subject has an earing plummets\n",
        "when we remove the pixel exactly where the earring is at.  This is a\n",
        "good sign that our algorithm is doing something appropriate.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}