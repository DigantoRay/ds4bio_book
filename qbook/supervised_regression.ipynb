{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prediction with regression\n",
        "\n",
        "Recall, we discussed a strict threshold classifier with accuracy as\n",
        "the loss function. Now consider continuous prediction, we need a loss\n",
        "function. A reasonable strategy would be to minimize the squared\n",
        "distances between our predictions and the observed values. In other\n",
        "words, $\\sum_{i=1}^n (Y_i - \\hat \\mu_i)^2.$\n",
        "\n",
        "If we were to dived this by $n$, it would be the average of the\n",
        "squared errors, or the *mean squared error* (MSE). We can use\n",
        "minimizing the squared error both as a rule for finding a good\n",
        "prediction and as our evaluation strategy for held out data.\n",
        "\n",
        "What's left is to figure out how to come up with $\\hat \\mu_i$, our\n",
        "predictions for the observation $Y_i$. We previously considered just a\n",
        "rescaled version of $X$, our predictor, using regression through the\n",
        "origin. In this module, we'll try a slightly more complex model that\n",
        "includes a location (intercept) shift and a scale factor (slope). The\n",
        "consequence will be to fit the best line, in a certain sense, through\n",
        "our $X$, $Y$ paired data.\n",
        "\n",
        "To tie ourselves down with an example, consider the previous lecture's\n",
        "example, consider trying to get the FLAIR value from the other,\n",
        "non-FLAIR, imaging values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from scipy import stats as st\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "## this sets some style parameters\n",
        "sns.set()\n",
        "\n",
        "## Read in the data and display a few rows\n",
        "dat = pd.read_csv(\"https://raw.githubusercontent.com/bcaffo/ds4bme_intro/master/data/oasis.csv\")\n",
        "dat.head(4) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at the non-smoothed data (omitting the `_10` and `_20`)\n",
        "using a pair plot. I'm color coding by whether or not the specific\n",
        "voxel is a lesion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.pairplot(dat, vars = ['FLAIR', 'PD', 'T1', 'T2'], hue = 'GOLD_Lesions');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "T2 and PD (proton density) look pretty linearly related. Imagine a\n",
        "study where a researcher collected T2 but did not collect PD. Let's\n",
        "try to predict their PD values from the T2 values using a line. We'll\n",
        "use least squares as the loss function. Specifically\n",
        "\n",
        "$$\n",
        "\\sum_{v=1}^V (PD_v - \\beta_0 - \\beta_1 T2_v)^2\n",
        "$$\n",
        "\n",
        "where $v$ stands for voxel and $PD_v$ for the PD value at voxel $v$,\n",
        "$T2_v$ as the T2 value at voxel $v$ and $\\beta_0$ and $\\beta_1$ are\n",
        "parameters that we have to learn.\n",
        "\n",
        "A general equation for fitting a line to data is\n",
        "\n",
        "$$\n",
        "\\sum_{i=1}^n (Y_i - \\beta_0 - \\beta_1 X_i)^2\n",
        "$$\n",
        "\n",
        "where we want to use $X_i$ to predict $Y_i$. \n",
        "\n",
        "It turns out that $\\beta_0$ and $\\beta_1$ have optimal solutions that\n",
        "we can write down. We get\n",
        "\n",
        "$$\n",
        "\\hat \\beta_1 = Cor(X, Y) \\frac{SD_Y}{SD_X}\n",
        "$$\n",
        "\n",
        "where $Cor(X, Y)$ is the (Pearson) **correlation** between $X$ and $Y$\n",
        "and $SD_X$ is the **standard deviation** of $X$ (and $SD_Y$ is for\n",
        "$Y$). The intercept satisfies\n",
        "\n",
        "$$\n",
        "\\hat \\beta_0 = \\bar Y - \\bar X \\hat \\beta_1\n",
        "$$\n",
        "\n",
        "where $\\bar X$ and $\\bar Y$ are the means. \n",
        "\n",
        "Notice this latter equation reorganized is just\n",
        "\n",
        "$$\n",
        "\\bar Y = \\hat \\beta_0 + \\bar X \\hat \\beta_1\n",
        "$$\n",
        "\n",
        "pointing out that the fitted line has to go through the point $(\\bar X, \\bar Y)$. \n",
        "\n",
        "## Some definitions\n",
        "* The **covariance** is defined as  $Cov(X,Y) = \\sum_{i=1}^n (Y_i - \\bar Y) (X_i - \\bar X) / (N-1)$\n",
        "* The **standard deviation** of $X$ is $SD_X$, $\\sqrt{Cov(X, X)}$\n",
        "* The Pearson **correlation** is defined as $\\frac{Cov(X, Y)}{SD_X \\times SD_Y}$\n",
        "\n",
        "The Pearson correlation measures the degree of linear association\n",
        "between two variables where neither is thought of as an outcome or\n",
        "predictor. It is a unit free quantity. If you just say \"correlation\"\n",
        "without further context, it's understood to mean the Pearson\n",
        "correlation. The covariance measures the same thing, though it has the\n",
        "units of the units X times the units of Y. The sample standard\n",
        "deviation of X has the units of X and measures the spread, or\n",
        "variability, of X. The variance, $Cov(X, X)$, is simply the square of\n",
        "the standard deviation and has units of X squared."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "x = dat['T2']\n",
        "y = dat['PD']\n",
        "trainFraction = 0.75\n",
        "\n",
        "## Hold out data\n",
        "sample = np.random.uniform(size = 100) < trainFraction\n",
        "xtrain = x[ sample]\n",
        "ytrain = y[ sample]\n",
        "xtest =  x[~sample]\n",
        "ytest =  y[~sample]\n",
        "\n",
        "## get the slope on the training data\n",
        "beta1 = st.pearsonr(xtrain, ytrain)[0] * np.std(ytrain) / np.std(xtrain)\n",
        "beta0 = np.mean(ytrain) - np.mean(xtrain) * beta1\n",
        "print([beta0, beta1])\n",
        " \n",
        "sns.scatterplot(x = xtrain, y = ytrain)\n",
        "## add a line\n",
        "sns.lineplot(x=xtrain, y=beta0 + beta1 * xtrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(st.linregress(x = xtrain, y = ytrain))\n",
        "sns.regplot(x=xtrain, y=ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's now calculate our predictions on the test set. Recall, the test\n",
        "set was not used to come up with estimates of $\\beta_0$ and\n",
        "$\\beta_1$. We'll show the training MSE and the testing MSE as well as\n",
        "a plot of the test set actual Ys versus the predicted ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "yhat_test = beta0 + beta1 * xtest\n",
        "yhat_train = beta0 + beta1 * xtrain\n",
        "\n",
        "## claculate the MSE in the training and test sets\n",
        "print([ np.mean( (ytrain - yhat_train) ** 2), \n",
        "        np.mean( (ytest -  yhat_test) ** 2 ) ])\n",
        "\n",
        " \n",
        "sns.scatterplot(x = yhat_test, y = ytest)\n",
        "plt.xlabel('Predicted value from xtest T2 values')\n",
        "plt.ylabel('Actual PD value from ytest')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}